{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd4SVfDxz5aw"
      },
      "source": [
        "# Localisation et détection d'objet\n",
        "\n",
        "Dans ce TP, nous allons mettre en pratique certaines des méthodes présentées en cours pour localiser des objets dans une image.\n",
        "\n",
        "En localisation et détection, on cherche à déterminer la position d'un objet, ainsi que sa classe, sous la forme d'une boîte englobante de largeur $b_w$ et hauteur $b_h$, et dont le centre a pour coordonnées le point $(b_x, b_y)$.\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1_jHHv6ZDe-3Xz25jIZ6o177laBEfmMRR\" style=\"width:500;height:300px;\"></center>\n",
        "<caption><center> Figure 1: Modèle de boîte englobante utilisé pour la localisation </center></caption>\n",
        "\n",
        "Le problème de localisation considère qu'un seul objet est présent sur l'image, alors que le problème de détection cherche à déterminer l'ensemble des objets présents sur l'image.\n",
        "\n",
        "\n",
        "\n",
        "Pour commencer, récupérez les images de la base de données :\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2ZjveWpbuNeV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'mangeoires_loc'...\n",
            "Updating files:  54% (1264/2330)\n",
            "Updating files:  55% (1282/2330)\n",
            "Updating files:  56% (1305/2330)\n",
            "Updating files:  57% (1329/2330)\n",
            "Updating files:  58% (1352/2330)\n",
            "Updating files:  59% (1375/2330)\n",
            "Updating files:  60% (1398/2330)\n",
            "Updating files:  61% (1422/2330)\n",
            "Updating files:  62% (1445/2330)\n",
            "Updating files:  63% (1468/2330)\n",
            "Updating files:  64% (1492/2330)\n",
            "Updating files:  65% (1515/2330)\n",
            "Updating files:  66% (1538/2330)\n",
            "Updating files:  67% (1562/2330)\n",
            "Updating files:  68% (1585/2330)\n",
            "Updating files:  69% (1608/2330)\n",
            "Updating files:  70% (1631/2330)\n",
            "Updating files:  71% (1655/2330)\n",
            "Updating files:  72% (1678/2330)\n",
            "Updating files:  73% (1701/2330)\n",
            "Updating files:  74% (1725/2330)\n",
            "Updating files:  75% (1748/2330)\n",
            "Updating files:  76% (1771/2330)\n",
            "Updating files:  77% (1795/2330)\n",
            "Updating files:  78% (1818/2330)\n",
            "Updating files:  79% (1841/2330)\n",
            "Updating files:  80% (1864/2330)\n",
            "Updating files:  81% (1888/2330)\n",
            "Updating files:  82% (1911/2330)\n",
            "Updating files:  83% (1934/2330)\n",
            "Updating files:  84% (1958/2330)\n",
            "Updating files:  85% (1981/2330)\n",
            "Updating files:  86% (2004/2330)\n",
            "Updating files:  87% (2028/2330)\n",
            "Updating files:  88% (2051/2330)\n",
            "Updating files:  89% (2074/2330)\n",
            "Updating files:  90% (2097/2330)\n",
            "Updating files:  91% (2121/2330)\n",
            "Updating files:  92% (2144/2330)\n",
            "Updating files:  93% (2167/2330)\n",
            "Updating files:  94% (2191/2330)\n",
            "Updating files:  95% (2214/2330)\n",
            "Updating files:  96% (2237/2330)\n",
            "Updating files:  97% (2261/2330)\n",
            "Updating files:  98% (2284/2330)\n",
            "Updating files:  99% (2307/2330)\n",
            "Updating files: 100% (2330/2330)\n",
            "Updating files: 100% (2330/2330), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/axelcarlier/mangeoires_loc.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF6aRZLE2-Yl"
      },
      "source": [
        "La base de données consiste en des photographies prises par une caméra reliée à une Raspberry Pi, cachée dans une mangeoire. Plusieurs mangeoires sont disséminées dans la nature en Occitanie, et l'objectif de [ce projet](https://econect.cnrs.fr/) est la reconnaissance des espèces et le comptage des individus qui viennent se poser devant le caméra, afin de suivre l'évolution des populations d'oiseaux et ainsi monitorer la biodiversité.\n",
        "\n",
        "La base de données qui vous est fournie regroupe 11 espèces d'animaux, majoritairement des oiseaux, désignés par un code :\n",
        "\n",
        "1. Mésange charbonnière (**MESCHA**)\n",
        "2. Verdier d'Europe (**VEREUR**)\n",
        "3. Écureuil roux (**ECUROU**)\n",
        "4. Pie bavarde (**PIEBAV**)\n",
        "5. Sittelle torchepot (**SITTOR**)\n",
        "6. Pinson des arbres (**PINARB**)\n",
        "7. Mésange noire (**MESNOI**)\n",
        "8. Mésange nonnette (**MESNON**)\n",
        "9. Mésange bleue (**MESBLE**)\n",
        "10. Rouge-gorge (**ROUGOR**)\n",
        "11. Accenteur mouchet (**ACCMOU**)\n",
        "\n",
        "\n",
        "\n",
        "<center> <img src=\"https://drive.google.com/uc?id=1Eit86N4D0Ea7ai1rBa0o-GmTwckhP9i0\" width=200>\n",
        "<img src=\"https://drive.google.com/uc?id=1lC7WL93UqDT_KV2m21yx99N5dkf98nCY\" width=200>\n",
        "<img src=\"https://drive.google.com/uc?id=10tzJORcSrSckDWmBDBtc8FUirxdbRxri\" width=200>\n",
        "<img src=\"https://drive.google.com/uc?id=1IHZp_B6bc8bADtAReRHhcyOjDQZAXDBQ\" width=200></center>\n",
        "<caption><center> Figure 2: Exemples d'images de la base de données </center></caption>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxZ6cVouz9Lp"
      },
      "source": [
        "# Localisation et classification d'objet\n",
        "\n",
        "Dans cette partie, nous allons nous concentrer sur le problème de la localisation d'un seul objet par classe. La base de données a été épurée pour se concentrer uniquement sur ce cas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBA3fa8RSDpt"
      },
      "outputs": [],
      "source": [
        "import PIL\n",
        "from PIL import Image\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKRm5oT-_Qsw"
      },
      "source": [
        "## Préparation des données\n",
        "\n",
        "Le code ci-dessous permet de charger les données et les formater pour la classification. Prenez le temps de regarder un peu le format des labels $y$.\n",
        "Notez que les images sont rendues carrées lors du chargement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q54zSuMvGM-5"
      },
      "outputs": [],
      "source": [
        "# Lecture du CSV contenant les informations relatives à la base de données\n",
        "dataset = []\n",
        "with open('mangeoires_loc/bd_mangeoires_equilibre.csv', newline='') as csvfile:\n",
        "\tfilereader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
        "\tfor row in filereader:\n",
        "\t\tdata = row[0].split(',')\n",
        "\t\tif data[0] != 'Data':\n",
        "\t\t\tbox = [float(data[5]), float(data[6]), float(data[7]), float(data[8])]\n",
        "\t\t\tnew_entry = {'type': data[0], 'specie': data[1], 'path': data[2], 'shape': [float(data[3]), float(data[4])], 'box': box}\n",
        "\t\t\tdataset.append(new_entry)\n",
        "\n",
        "# Nombre de classes de la base de données et intitulé des classes\n",
        "class_labels = list(dict.fromkeys([item['specie'] for item in dataset]))\n",
        "num_classes = len(class_labels)\n",
        "\n",
        "# Extraction des données d'apprentissage et de test\n",
        "dataset_train = [item for item in dataset if item['type']=='TRAIN']\n",
        "dataset_test = [item for item in dataset if item['type']=='TEST']\n",
        "\n",
        "print(class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPzqdJBVJLWJ"
      },
      "outputs": [],
      "source": [
        "def build_localization_tensors(image_size, dataset, num_classes):\n",
        "  # Préparation des structures de données pour x et y\n",
        "  x = np.zeros((len(dataset), image_size, image_size, 3))\n",
        "  y = np.empty((len(dataset), num_classes + 5)) # 1 + 4 + num_classes : présence / boîte englobante / classes\n",
        "\n",
        "  # Compteur de parcours du dataset\n",
        "  i = 0\n",
        "\n",
        "  for item in dataset:\n",
        "    # Lecture de l'image\n",
        "    img = Image.open('mangeoires_loc/' + item['path'])\n",
        "    # Mise à l'échelle de l'image\n",
        "    img = img.resize((image_size,image_size), Image.ANTIALIAS)\n",
        "    # Remplissage de la variable x\n",
        "    x[i] = np.asarray(img)\n",
        "\n",
        "    y[i, 0] = 1 # Un objet est toujours présent !\n",
        "\n",
        "    # Coordonnées de boîte englobante\n",
        "    img_shape = item['shape']\n",
        "    box = item['box']\n",
        "    bx = (box[0] + (box[2] - box[0])/2)/img_shape[0]\n",
        "    by = (box[1] + (box[3] - box[1])/2)/img_shape[1]\n",
        "    bw = (box[2] - box[0])/img_shape[0]\n",
        "    bh = (box[3] - box[1])/img_shape[1]\n",
        "    y[i, 1] = bx\n",
        "    y[i, 2] = by\n",
        "    y[i, 3] = bw\n",
        "    y[i, 4] = bh\n",
        "\n",
        "    # Probabilités de classe, sous la forme d'une one-hot vector\n",
        "    label = class_labels.index(item['specie'])\n",
        "    classes_probabilities = keras.utils.to_categorical(label, num_classes=num_classes)\n",
        "    y[i, 5:] = classes_probabilities\n",
        "\n",
        "    i = i+1\n",
        "\n",
        "  return x, y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnlljZWc_i1L"
      },
      "source": [
        "Séparation des données d'entraînement pour extraire un ensemble de validation, et pré-traitement des données."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJLRiuFX_VPL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Pour la suite du TP on considèrera des images de taille 64x64x3\n",
        "# Augmenter cette valeur donnerait de meilleurs résultats mais nécessiterait des calculs plus long.\n",
        "IMAGE_SIZE = 64\n",
        "\n",
        "# Lecture des données d'entraînement et de test\n",
        "x, y = build_localization_tensors(IMAGE_SIZE, dataset_train, num_classes)\n",
        "x_test, y_test = build_localization_tensors(IMAGE_SIZE, dataset_test, num_classes)\n",
        "\n",
        "#Extraction d'un ensemble de validation\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.10, random_state=42)\n",
        "\n",
        "# Pour améliorer l'entraînement, on peut centrer-réduire les coordonnées des bounding boxes...\n",
        "y_std = np.std(y_train, axis=0)\n",
        "y_mean = np.mean(y_train, axis=0)\n",
        "y_train[...,1:5] = (y_train[...,1:5] - y_mean[1:5])/y_std[1:5]\n",
        "y_val[...,1:5] = (y_val[...,1:5] - y_mean[1:5])/y_std[1:5]\n",
        "y_test[...,1:5] = (y_test[...,1:5] - y_mean[1:5])/y_std[1:5]\n",
        "\n",
        "# ... et normaliser les valeurs de couleur\n",
        "x_train = x_train/255\n",
        "x_val = x_val/255\n",
        "x_test = x_test/255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE4wQYq3AKnA"
      },
      "source": [
        "## Fonctions utiles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6NBpMtaM-C0"
      },
      "source": [
        "Une fonction de calcul de l'intersection sur union, qui nous sera utile pour les métriques d'évaluation de nos méthodes :\n",
        "\n",
        "$$ IoU (R_1, R_2) = \\frac{\\mathcal{A} (R_1 \\cap R_2)}{\\mathcal{A} (R_1 \\cup R_2)} = \\frac{\\mathcal{A} (R_1 \\cap R_2)}{\\mathcal{A} (R_1) + \\mathcal{A} (R_2) -  \\mathcal{A} (R_1 \\cap R_2)} $$\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1BQx2kDOCltZ_5gcnKVWTVUVNmGk-7qBC\" width=500>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr-O1XuwLoL3"
      },
      "outputs": [],
      "source": [
        "### A COMPLETER\n",
        "def intersection_sur_union(box1, box2):\n",
        "  \"\"\"\n",
        "  Calcul de l'intersection sur union entre deux rectangles box1 et box2\n",
        "\n",
        "  Arguments:\n",
        "  box1, box2 -- les coordonnées des deux rectangles, chacun sous la forme [cx, cy, w, h]\n",
        "                où (cx, cy) désigne les coordonnées du centre du rectangle,\n",
        "                w sa largeur et h sa hauteur\n",
        "  \n",
        "  \n",
        "  Retourne :\n",
        "  iou -- la valeur d'intersection sur union entre les deux rectangles\n",
        "  \"\"\"\n",
        "  \n",
        "  \n",
        "  x1 = max(box1[0] - box1[2]/2, box2[0] - box2[2]/2)\n",
        "  y1 = max(box1[1] - box1[3]/2, box2[1] - box2[3]/2)\n",
        "  x2 = min(box1[0] + box1[2]/2, box2[0] + box2[2]/2)\n",
        "  y2 = min(box1[1] + box1[3]/2, box2[1] + box2[3]/2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdqAFWFxRx8l"
      },
      "outputs": [],
      "source": [
        "print(intersection_sur_union([2.5, 2, 1, 4], [2, 3, 4, 2]))  # Résultat attendu : 0.2\n",
        "print(intersection_sur_union([2.5, 2, 1, 4], [5, 3, 4, 2]))  # Résultat attendu : 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLpMJGi3QC9i"
      },
      "source": [
        "Calcul des différentes métriques :\n",
        "\n",
        "$$ P = \\frac{TP}{TP + FP} $$\n",
        "\n",
        "$$ R = \\frac{TP}{TP + FN} $$\n",
        "\n",
        "$$ F1 = \\frac{2 * P * R}{P + R} $$\n",
        "\n",
        "où $TP$ désigne le nombre de vrais positifs, $FP$ le nombre de faux positifs, $FN$ le nombre de faux négatifs, $P$ la précision, $R$ le rappel et $F1$ le F1-score.\n",
        "\n",
        "On considère souvent qu'une détection est correcte si la classification est valide et que l'intersection sur union entre vérité terrain et prédiction est supérieure à 0.5 (on utilisera un seuil modifiable *iou_thres*)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5e_aIvjXLq32"
      },
      "outputs": [],
      "source": [
        "# A COMPLETER\n",
        "def global_accuracy(y_true, y_pred, iou_thres=0.5):\n",
        "  \"\"\"\n",
        "  Calcul, pour chaque classe de la précision, du rappel et du F1-score ainsi\n",
        "  que du pourcentage global de bonnes détections.\n",
        "\n",
        "  Arguments:\n",
        "  y_true -- les labels de la vérité terrain, de dimension (M, 1+4+N) où M désigne\n",
        "          le nombre d'éléments du dataset et N le nombre de classes (11 dans notre cas)\n",
        "  y_pred -- les labels prédits par un modèle, de dimension (M, 1+4+N)\n",
        "  iou_thres -- seuil d'intersection sur union entre une boîte \"vérité-terrain\" et\n",
        "              une boite prédite au-dessus duquel on considère que la prédiction est correcte\n",
        "\n",
        "  Retourne :\n",
        "  class_res -- liste de longueur N contenant des dictionnaires sous la forme\n",
        "            {\"Précision\": p, \"Rappel\": r, \"F-score\": f} résumant les métriques\n",
        "            précision, rappel et F1-score pour chacune des classes.\n",
        "  accuracy -- pourcentage global de bonnes détections\n",
        "  \"\"\"\n",
        "  # Initialisation des métriques : nombre de vrais positifs (TP), faux positifs (FP)\n",
        "  # et faux négatifs (FN) pour chaque classe\n",
        "  class_metrics = []\n",
        "  for i in range(num_classes):\n",
        "    class_metrics.append({'TP': 0, 'FP': 0, 'FN': 0})\n",
        "\n",
        "  # Nombres de détections correctes et de détections incorrectes\n",
        "  total_correct_detections = 0\n",
        "  total_incorrect_detections = 0\n",
        "  for i in range(y_true.shape[0]):\n",
        "    # Labels vérité-terrain et prédits\n",
        "    groundtruth_label = np.argmax(y_true[i,5:])\n",
        "    predicted_label = np.argmax(y_pred[i,5:])\n",
        "\n",
        "    # Coordonnées de boîtes englobantes réelles et prédites\n",
        "    bx_true = (y_true[i,1]*y_std[1] + y_mean[1])\n",
        "    by_true = (y_true[i,2]*y_std[2] + y_mean[2])\n",
        "    bw_true = (y_true[i,3]*y_std[3] + y_mean[3])\n",
        "    bh_true = (y_true[i,4]*y_std[4] + y_mean[4])\n",
        "    bx_pred = (y_pred[i,1]*y_std[1] + y_mean[1])\n",
        "    by_pred = (y_pred[i,2]*y_std[2] + y_mean[2])\n",
        "    bw_pred = (y_pred[i,3]*y_std[3] + y_mean[3])\n",
        "    bh_pred = (y_pred[i,4]*y_std[4] + y_mean[4])\n",
        "\n",
        "    # Calcul de l'intersection sur union\n",
        "    iou = intersection_sur_union([bx_true, by_true, bw_true, bh_true], [bx_pred, by_pred, bw_pred, bh_pred])\n",
        "\n",
        "    ### A COMPLETER\n",
        "    # Si la détection est correcte :\n",
        "    if groundtruth_label == predicted_label and iou > iou_thres:\n",
        "      \n",
        "      # Mise à jour des vrais positifs\n",
        "      class_metrics[groundtruth_label]['TP'] += 1\n",
        "      total_correct_detections += 1\n",
        "    else:\n",
        "      # Mise à jour des faux positifs et des faux négatifs\n",
        "      class_metrics[groundtruth_label]['FN'] += 1\n",
        "      class_metrics[predicted_label]['FP'] += 1\n",
        "      total_incorrect_detections += 1\n",
        "      \n",
        "\n",
        "  class_res = []\n",
        "  for i in range(num_classes):\n",
        "    P = class_metrics[i]['TP'] / (class_metrics[i]['TP'] + class_metrics[i]['FP'])\n",
        "    R = ...\n",
        "    F_score = ...\n",
        "    class_res.append({'Precision': P, 'Rappel': R, 'F-score': F_score})\n",
        "\n",
        "  accuracy = \n",
        "  ### FIN\n",
        "  return class_res, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOOWhuk4VBZE"
      },
      "outputs": [],
      "source": [
        "num_class_test = 3\n",
        "class_labels_test = ['Classe 1', 'Classe 2', 'Classe 3']\n",
        "y_true_test = np.ones((num_class_test,8))\n",
        "y_true_test[0,:2] = [0.5, 0.5]\n",
        "y_true_test[0, 5:] = [1, 0, 0]\n",
        "y_true_test[1,:2] = [0.5, 0.5]\n",
        "y_true_test[1, 5:] = [0, 1, 0]\n",
        "y_true_test[2,:2] = [0.5, 0.5]\n",
        "y_true_test[2, 5:] = [0, 0, 1]\n",
        "y_pred_test = np.ones((num_class_test,8))\n",
        "y_pred_test[0,:2] = [0.6, 0.6]\n",
        "y_pred_test[0, 5:] = [1, 0, 0]\n",
        "y_pred_test[1,:2] = [2.5, 2.5]\n",
        "y_pred_test[1, 5:] = [0, 0, 1]\n",
        "y_pred_test[2,:2] = [0.6, 0.6]\n",
        "y_pred_test[2, 5:] = [0, 0, 1]\n",
        "\n",
        "class_res_test, acc_test = global_accuracy(y_true_test, y_pred_test)\n",
        "\n",
        "print(f\"La précision globale est de {acc_test:.1f}%\")\n",
        "\n",
        "print()\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"|  Classe  | Précision | Rappel | F1-score |\")\n",
        "print(\"--------------------------------------------\")\n",
        "for i in range(num_class_test):\n",
        "  print(f\"| {class_labels_test[i]:9s}|   {class_res_test[i]['Precision']:.2f}    |  {class_res_test[i]['Rappel']:.2f}  |   {class_res_test[i]['F-score']:.2f}   |\")\n",
        "  print(\"--------------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1Tg4VFVVB-w"
      },
      "source": [
        "**Affichage attendu :**\n",
        "```\n",
        "La précision globale est de 66.7%\n",
        "\n",
        "--------------------------------------------\n",
        "|  Classe  | Précision | Rappel | F1-score |\n",
        "--------------------------------------------\n",
        "| Classe 1 |   1.00    |  1.00  |   1.00   |\n",
        "--------------------------------------------\n",
        "| Classe 2 |   0.00    |  0.00  |   0.00   |\n",
        "--------------------------------------------\n",
        "| Classe 3 |   0.50    |  1.00  |   0.67   |\n",
        "--------------------------------------------\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMntCEgkANMg"
      },
      "source": [
        "La fonction ci-dessous permet de calculer l'intersection sur union  sur des tenseurs (et non des tableaux numpy), elle sera donc utilisable comme métrique pendant l'entraînement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVk9cB1WAMUK"
      },
      "outputs": [],
      "source": [
        "def compute_iou(y_true, y_pred):\n",
        "  ### \"Dénormalisation\" des coordonnées des boîtes englobantes\n",
        "  pred_box_xy = y_pred[..., 0:2]* y_std[0:2] + y_mean[0:2]\n",
        "  true_box_xy = y_true[..., 0:2]* y_std[0:2] + y_mean[0:2]\n",
        "\n",
        "  ### \"Dénormalisation\" des largeur et hauteur des boîtes englobantes\n",
        "  pred_box_wh = y_pred[..., 2:4] * y_std[2:4] + y_mean[2:4]\n",
        "  true_box_wh = y_true[..., 2:4] * y_std[2:4] + y_mean[2:4]\n",
        "\n",
        "  # Calcul des coordonnées minimales et maximales des boiptes englobantes réelles\n",
        "  true_wh_half = true_box_wh / 2.\n",
        "  true_mins    = true_box_xy - true_wh_half\n",
        "  true_maxes   = true_box_xy + true_wh_half\n",
        "\n",
        "  # Calcul des coordonnées minimales et maximales des boiptes englobantes prédites\n",
        "  pred_wh_half = pred_box_wh / 2.\n",
        "  pred_mins    = pred_box_xy - pred_wh_half\n",
        "  pred_maxes   = pred_box_xy + pred_wh_half\n",
        "\n",
        "  # Détermination de l'intersection des boîtes englobantes\n",
        "  intersect_mins  = tf.maximum(pred_mins,  true_mins)\n",
        "  intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
        "  intersect_wh    = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "  intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "\n",
        "  # Aire des boîtes englobantes prédites et réelles\n",
        "  true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
        "  pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
        "\n",
        "  # Aire de l'union des boîtes prédites et réelles\n",
        "  union_areas = pred_areas + true_areas - intersect_areas\n",
        "\n",
        "  iou_scores  = tf.truediv(intersect_areas, union_areas)\n",
        "  return iou_scores\n",
        "\n",
        "def iou():\n",
        "  def iou_metrics(y_true, y_pred):\n",
        "    return compute_iou(y_true, y_pred)\n",
        "  iou_metrics.__name__= \"IoU\"\n",
        "  return iou_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vidE3XHlAkst"
      },
      "source": [
        "Visualisation des données et labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yotZHKgAiV1"
      },
      "outputs": [],
      "source": [
        "# Si seuls x et y sont indiqués, on tire au hasard un numéro d'image et on affiche le label y associé  à l'image\n",
        "# Si un 2e y, nommé y_pred, est indiqué, alors les deux labels sont affichés côte à côte, afin de pouvoir les comparer\n",
        "# Enfin on peut également indiquer l'id de l'image que l'on souhaite visualiser.\n",
        "def print_data_localisation(x, y, y_pred=[], id=None, image_size=64):\n",
        "  if id==None:\n",
        "    # Tirage aléatoire d'une image dans la base\n",
        "    num_img = np.random.randint(x.shape[0]-1)\n",
        "  else:\n",
        "    num_img = id\n",
        "\n",
        "  img = x[num_img]\n",
        "  lab = y[num_img]\n",
        "\n",
        "  colors = [\"blue\", \"yellow\", \"red\", \"orange\", \"coral\", \"gold\", \"ivory\", \"fuchsia\", \"purple\", \"cyan\", \"navy\"] # Différentes couleurs pour les différentes classes\n",
        "  classes = ['MESCHA', 'VEREUR', 'ECUROU', 'PIEBAV', 'SITTOR', 'PINARB', 'MESNOI', 'MESNON', 'MESBLE', 'ROUGOR', 'ACCMOU']\n",
        "\n",
        "  if np.any(y_pred):\n",
        "    plt.subplot(1, 2, 1)\n",
        "\n",
        "  # Affichage de l'image\n",
        "  plt.imshow(img)\n",
        "  # Détermination de la classe\n",
        "  class_id = np.argmax(lab[5:])\n",
        "\n",
        "  # Détermination des coordonnées de la boîte englobante dans le repère image\n",
        "  ax = (lab[1]*y_std[1] + y_mean[1]) * image_size\n",
        "  ay = (lab[2]*y_std[2] + y_mean[2]) * image_size\n",
        "  width = (lab[3]*y_std[3] + y_mean[3]) * image_size\n",
        "  height = (lab[4]*y_std[4] + y_mean[4]) * image_size\n",
        "  #print(\"x: {}, y: {}, w: {}, h:{}\".format(ax,ay,width, height))\n",
        "  # Détermination des extrema de la boîte englobante\n",
        "  p_x = [ax-width/2, ax+width/2]\n",
        "  p_y = [ay-height/2, ay+height/2]\n",
        "  # Affichage de la boîte englobante, dans la bonne couleur\n",
        "  plt.plot([p_x[0], p_x[0]],p_y,color=colors[class_id])\n",
        "  plt.plot([p_x[1], p_x[1]],p_y,color=colors[class_id])\n",
        "  plt.plot(p_x,[p_y[0],p_y[0]],color=colors[class_id])\n",
        "  plt.plot(p_x,[p_y[1],p_y[1]],color=colors[class_id])\n",
        "  plt.title(\"Vérité Terrain : Image {} - {}\".format(num_img, classes[class_id]))\n",
        "\n",
        "  if np.any(y_pred):\n",
        "    plt.subplot(1, 2, 2)\n",
        "    # Affichage de l'image\n",
        "    plt.imshow(img)\n",
        "    lab = y_pred[num_img]\n",
        "    # Détermination de la classe\n",
        "    class_id = np.argmax(lab[5:])\n",
        "\n",
        "    # Détermination des coordonnées de la boîte englobante dans le repère image\n",
        "    ax = (lab[1]*y_std[1] + y_mean[1]) * image_size\n",
        "    ay = (lab[2]*y_std[2] + y_mean[2]) * image_size\n",
        "    width = (lab[3]*y_std[3] + y_mean[3]) * image_size\n",
        "    height = (lab[4]*y_std[4] + y_mean[4]) * image_size\n",
        "    #print(\"x: {}, y: {}, w: {}, h:{}\".format(ax,ay,width, height))\n",
        "    # Détermination des extrema de la boîte englobante\n",
        "    p_x = [ax-width/2, ax+width/2]\n",
        "    p_y = [ay-height/2, ay+height/2]\n",
        "    # Affichage de la boîte englobante, dans la bonne couleur\n",
        "    plt.plot([p_x[0], p_x[0]],p_y,color=colors[class_id])\n",
        "    plt.plot([p_x[1], p_x[1]],p_y,color=colors[class_id])\n",
        "    plt.plot(p_x,[p_y[0],p_y[0]],color=colors[class_id])\n",
        "    plt.plot(p_x,[p_y[1],p_y[1]],color=colors[class_id])\n",
        "    plt.title(\"Prédiction : Image {} - {}\".format(num_img, classes[class_id]))\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "for i in range(10):#x.shape[0]):\n",
        "    print_data_localisation(x_train, y_train, image_size=IMAGE_SIZE, id=i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE9_B3yuR4OH"
      },
      "source": [
        "Fonction d'affichage des courbes d'apprentissage et de validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6O7R3qnCtlN"
      },
      "outputs": [],
      "source": [
        "def plot_training_analysis(history, metric='loss'):\n",
        "\n",
        "  loss = history.history[metric]\n",
        "  val_loss = history.history['val_' + metric]\n",
        "\n",
        "  epochs = range(len(loss))\n",
        "\n",
        "  plt.plot(epochs, loss, 'b', linestyle=\"--\",label='Training ' + metric)\n",
        "  plt.plot(epochs, val_loss, 'g', label='Validation ' + metric)\n",
        "  plt.title('Training and validation ' + metric)\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F_l_yNlDapa"
      },
      "source": [
        "## Travail à faire\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6D31NGPNyJp"
      },
      "source": [
        "<center> <img src=\"https://drive.google.com/uc?id=1YzCZe4pgnjJDVGklAaCHZ7HhlPJsadg9\" width=500></center>\n",
        "<caption><center> Figure 3: Illustration de l'architecture du réseau à construire.  </center></caption>\n",
        "\n",
        "Complétez les codes qui vous sont fournis pour obtenir un algorithme de localisation.\n",
        "Vous pouvez utiliser n'importe quelle base convolutive de votre choix (**commencez par exemple par réutiliser celle que vous avez implémenté au TP3**), en revanche vous devrez porter une attention particulière à la couche de sortie.\n",
        "\n",
        "Vous allez en fait produire 3 sorties différentes : une caractérisant la présence d'un objet, une autre fournissant les coordonnées de la boîte englobante, et enfin une dernière effectuant la classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPOXiJ7hDcbr"
      },
      "outputs": [],
      "source": [
        "def create_model_localisation(input_shape=(64, 64, 3)):\n",
        "\n",
        "  input_layer = Input(shape=input_shape)\n",
        "\n",
        "\n",
        "  conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "  \n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "  \n",
        "  conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "  \n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "  \n",
        "  conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "  \n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "  \n",
        "  conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "  \n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "  # Convolutions, Pooling, Dense,  à vous de former votre réseau\n",
        "  \n",
        "  # Votre dernière couche doit mettre à jour une variable prev_layer, réutilisée dans les couches de sortie ci-dessous\n",
        "  prev_layer = Flatten()(pool4)\n",
        "   \n",
        "  # Sortie caractérisant la présence d'un objet\n",
        "  output_p = Dense(1, activation='sigmoid', name='presence')(prev_layer)\n",
        "  # Sortie caractérisant les coordonnées de boîte englobante\n",
        "  output_coord = Dense(4,activation = 'linear', name='bounding_box')(prev_layer)\n",
        "  \n",
        "  # Sortie caractérisant les probabilités de classe\n",
        "  output_class = Dense(num_classes, activation='softmax', name='classes')(prev_layer)\n",
        "\n",
        "  output= [output_p, output_coord, output_class]\n",
        "  model = Model(input_layer, output)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYoVYfQpotjy"
      },
      "source": [
        "<center> <img src=\"https://drive.google.com/uc?id=1bnh8zU7Os-w-5TT8hV4xDoThKQc-Ywc2\" width=500></center>\n",
        "<caption><center> Figure 4: Illustration des fonctions de coût à utiliser pour l'entraînement. </center></caption>\n",
        "\n",
        "Pour entraîner votre réseau, vous allez donc devoir associer une fonction de coût à chacune des sorties du réseau. La fonction de coût totale sera la somme des trois fonctions de coût précédemment définies, pondérées par des poids définis dans la variable *loss_weights*.\n",
        "\n",
        "**Prenez le temps de tester différentes valeurs de *loss_weights* en fonction de l'évolution des métriques que vous observerez pendant l'entraînement.**\n",
        "\n",
        "Vous évaluerez vos résultats de manière qualitative (en affichant les boîtes englobantes prédites et réelles) mais aussi quantitatives grâce aux fonctions définies dans la section précédente. **N'hésitez pas à modifier un peu le paramètre iou_threshold positionné par défaut à 0.5** (une valeur de 0.4 vous permettra d'obtenir de meilleurs résultats !)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_ewlCn5Rovm"
      },
      "outputs": [],
      "source": [
        "batch_size=16\n",
        "model = create_model_localisation()\n",
        "opt = Adam(learning_rate=3e-4)\n",
        "\n",
        "# Ici mettre, dans l'ordre, les fonctions de coût associées à chacune des sorties\n",
        "loss=['binary_crossentropy', 'mean_squared_error', 'categorical_crossentropy']\n",
        "# On va associer une métrique à chaque sortie : l'accuracy pour les deux classifications,\n",
        "# et l'IoU définie plus tôt pour la qualité des boîtes englobantes.\n",
        "metrics=[ ['accuracy'], [iou()], ['accuracy']]\n",
        "loss_weights = [1, 1, 1]\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt,\n",
        "              metrics=metrics,\n",
        "              loss_weights=loss_weights\n",
        "              )\n",
        "history = model.fit(x_train, [y_train[:,0], y_train[:,1:5], y_train[:,5:]],\n",
        "              epochs=50,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_val, [y_val[:,0], y_val[:,1:5], y_val[:,5:]]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc-sGe8LNzA-"
      },
      "outputs": [],
      "source": [
        "# Analyse des résultats : courbes d'évolution de la fonction de perte, et de l'IoU des boîtes englobantes ainsi que de la précision des classes prédites\n",
        "plot_training_analysis(history, metric='loss')\n",
        "plot_training_analysis(history, metric='coord_IoU')\n",
        "plot_training_analysis(history, metric='classes_accuracy')\n",
        "\n",
        "# Prédiction des données de test\n",
        "y_pred_presence, y_pred_coords, y_pred_classes = model.predict(x_test)\n",
        "y_pred = np.zeros(y_test.shape)\n",
        "for i in range(y_pred.shape[0]):\n",
        "  y_pred[i, 0] = y_pred_presence[i]\n",
        "  y_pred[i, 1:5] = y_pred_coords[i]\n",
        "  y_pred[i, 5:] = y_pred_classes[i]\n",
        "\n",
        "# Affichage des résultats sur plusieurs images\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=1, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=2, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=3, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=4, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=5, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=6, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=7, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=8, image_size=IMAGE_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVU1bR_YEIMs"
      },
      "outputs": [],
      "source": [
        "class_res, accuracy = global_accuracy(y_test, y_pred)\n",
        "\n",
        "print(f\"La précision globale est de {accuracy:.1f}%\")\n",
        "\n",
        "print()\n",
        "print(\"------------------------------------------\")\n",
        "print(\"| Classe | Précision | Rappel | F1-score |\")\n",
        "print(\"------------------------------------------\")\n",
        "for i in range(num_classes):\n",
        "  print(f\"| {class_labels[i]:7s}|   {class_res[i]['Precision']:.2f}    |  {class_res[i]['Rappel']:.2f}  |   {class_res[i]['F-score']:.2f}   |\")\n",
        "  print(\"------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiFO6fBns-OI"
      },
      "source": [
        "En pratique, il est délicat de trouver une bonne combinaison des fonctions de perte tel que vous l'avez fait sur les cellules précédentes. L'entropie croisée et l'erreur quadratique moyenne donnent des valeurs trop différentes pour être combinables efficacement.\n",
        "\n",
        "Une variante, peut-être plus simple à faire fonctionner, est d'utiliser uniquement l'erreur quadratique moyenne comme perte pour toutes les sorties. C'est cette variante qui est implémentée dans l'algorithme YOLO, dont nous implémenterons une version simplifiée dans le prochain TP.\n",
        "Testez cette solution ci-dessous. Comme sur l'exercice précédent, n'hésitez pas à faire varier le poids des différents éléments de la fonction de coût."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttGCeqz0Dc3y"
      },
      "outputs": [],
      "source": [
        "batch_size=16\n",
        "model = create_model_localisation()\n",
        "opt = Adam(learning_rate=3e-4)\n",
        "\n",
        "loss = ['binary_crossentropy', 'mean_squared_error', 'categorical_crossentropy']\n",
        "metrics =[ ['accuracy'], [iou()], ['accuracy']]\n",
        "loss_weights = [1, 1, 1]\n",
        "\n",
        "model.compile(loss=loss,\n",
        "              optimizer=opt,\n",
        "              metrics=metrics,\n",
        "              loss_weights=loss_weights\n",
        "              )\n",
        "history = model.fit(x_train, [y_train[:,0], y_train[:,1:5], y_train[:,5:]],\n",
        "              epochs=50,\n",
        "              batch_size=batch_size,\n",
        "              validation_data=(x_val, [y_val[:,0], y_val[:,1:5], y_val[:,5:]]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKlN9-clJMrI"
      },
      "outputs": [],
      "source": [
        "# Analyse des résultats : courbes d'évolution de la fonction de perte, et de l'IoU des boîtes englobantes ainsi que de la précision des classes prédites\n",
        "plot_training_analysis(history, metric='loss')\n",
        "plot_training_analysis(history, metric='coord_IoU')\n",
        "plot_training_analysis(history, metric='classes_accuracy')\n",
        "\n",
        "# Prédiction des données de test\n",
        "y_pred_presence, y_pred_coords, y_pred_classes = model.predict(x_test)\n",
        "y_pred = np.zeros(y_test.shape)\n",
        "for i in range(y_pred.shape[0]):\n",
        "  y_pred[i, 0] = y_pred_presence[i]\n",
        "  y_pred[i, 1:5] = y_pred_coords[i]\n",
        "  y_pred[i, 5:] = y_pred_classes[i]\n",
        "\n",
        "# Affichage des résultats sur plusieurs images\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=1, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=2, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=3, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=4, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=5, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=6, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=7, image_size=IMAGE_SIZE)\n",
        "print_data_localisation(x_test, y_test, y_pred = y_pred, id=8, image_size=IMAGE_SIZE)\n",
        "\n",
        "\n",
        "class_res, accuracy = global_accuracy(y_test, y_pred, iou_thres=0.4)\n",
        "\n",
        "print(f\"La précision globale est de {accuracy:.1f}%\")\n",
        "\n",
        "print()\n",
        "print(\"------------------------------------------\")\n",
        "print(\"| Classe | Précision | Rappel | F1-score |\")\n",
        "print(\"------------------------------------------\")\n",
        "for i in range(num_classes):\n",
        "  print(f\"| {class_labels[i]:7s}|   {class_res[i]['Precision']:.2f}    |  {class_res[i]['Rappel']:.2f}  |   {class_res[i]['F-score']:.2f}   |\")\n",
        "  print(\"------------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stQpmnmAt_bf"
      },
      "source": [
        "Compte-tenu de la taille réduite de la base de données, les résultats ne sont pas mal du tout ! On observe quelques confusions entre certaines classes mais les prédictions sont souvent intéressantes.\n",
        "\n",
        "Il devrait cependant subsister un fort surapprentissage à ce stade. Comme nous l'avons vu dans de précédents TPs, vous avez plusieurs possibilités qui s'offrent à vous pour le corriger :\n",
        "\n",
        "*   Augmentation de la base de données. Vous pouvez pour cela vous appuyer sur l'exemple fourni en TP précédent, avec une classe *Sequence* et l'utilisation de la librairie *Albumentation*. Je vous fournis une Sequence qui fonctionne ci-dessous.\n",
        "*   Utilisation de *transfer learning* : partant d'un réseau entraîné sur ImageNet (qui contient de nombreuses classes d'animaux), vous bénéficieriez de filtres très généraux qui aiderait à limiter le surapprentissage.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jp6jwZidJgx"
      },
      "source": [
        "# Code fourni pour vous aider à mettre en place l'augmentation de données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5WuA43ZULxP"
      },
      "source": [
        "Définition des augmentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WS5wxAXvdJgx"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "from albumentations import (Compose, RandomBrightnessContrast, HorizontalFlip)\n",
        "import albumentations as A\n",
        "\n",
        "AUGMENTATIONS_TRAIN = Compose([\n",
        "    HorizontalFlip(),\n",
        "    RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5)\n",
        "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sND_uaWPURfE"
      },
      "source": [
        "Une sequence qui permet d'implanter l'augmentation de données :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9GXnEyYdJgy"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "class MangeoireSequence(Sequence):\n",
        "    # Initialisation de la séquence avec différents paramètres\n",
        "    def __init__(self, x_set, y_set, batch_size,augmentations):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.classes = ['MESCHA', 'VEREUR', 'ECUROU', 'PIEBAV', 'SITTOR', 'PINARB', 'MESNOI', 'MESNON', 'MESBLE', 'ROUGOR', 'ACCMOU']\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augmentations\n",
        "        self.indices1 = np.arange(x_set.shape[0])\n",
        "        np.random.shuffle(self.indices1) # Les indices permettent d'accéder\n",
        "        # aux données et sont randomisés à chaque epoch pour varier la composition\n",
        "        # des batches au cours de l'entraînement\n",
        "\n",
        "    # Fonction calculant le nombre de pas de descente du gradient par epoch\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    # Il y a des problèmes d'arrondi dans les conversions de boîtes englobantes\n",
        "    # internes à la librairie Albumentations\n",
        "    # Pour les contourner, si les boîtes sont trop proches des bords, on les érode un peu\n",
        "    def erode_bounding_box(self, box):\n",
        "        epsilon = 0.01\n",
        "\n",
        "        xmin = max(box[0] - box[2]/2, epsilon)\n",
        "        ymin = max(box[1] - box[3]/2, epsilon)\n",
        "        xmax = min(box[0] + box[2]/2, 1-epsilon)\n",
        "        ymax = min(box[1] + box[3]/2, 1-epsilon)\n",
        "\n",
        "        cx = xmin + (xmax - xmin)/2\n",
        "        cy = ymin + (ymax - ymin)/2\n",
        "        width = xmax - xmin\n",
        "        height = ymax - ymin\n",
        "\n",
        "        return np.array([cx, cy, width, height])\n",
        "\n",
        "    # Application de l'augmentation de données à chaque image du batch et aux\n",
        "    # boîtes englobantes associées\n",
        "    def apply_augmentation(self, bx, by):\n",
        "\n",
        "        batch_x = np.zeros((bx.shape[0], IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "        batch_y = by\n",
        "\n",
        "        # Pour chaque image du batch\n",
        "        for i in range(len(bx)):\n",
        "            bboxes = []\n",
        "            box = by[i,1:5]\n",
        "            # Dénormalisation des coordonnées de boites englobantes\n",
        "            box[0] = (box[0]*y_std[1] + y_mean[1])\n",
        "            box[1] = (box[1]*y_std[2] + y_mean[2])\n",
        "            box[2] = (box[2]*y_std[3] + y_mean[3])\n",
        "            box[3] = (box[3]*y_std[4] + y_mean[4])\n",
        "            box = self.erode_bounding_box(box)\n",
        "            bboxes.append(box)\n",
        "\n",
        "            class_labels = []\n",
        "            class_id = np.argmax(by[i, 5:])\n",
        "            class_labels.append(self.classes[class_id])\n",
        "\n",
        "            img = bx[i].astype('float32')\n",
        "\n",
        "            # Application de l'augmentation à l'image et aux masques\n",
        "            transformed = self.augment(image=img.astype('float32'), bboxes=bboxes, class_labels=class_labels)\n",
        "            batch_x[i] = transformed['image']\n",
        "            batch_y_transformed = transformed['bboxes']\n",
        "\n",
        "            # Renormalisation des coordonnées de boîte englobante transformée\n",
        "            batch_y[i, 1] = (batch_y_transformed[0][0] - y_mean[1])/y_std[1]\n",
        "            batch_y[i, 2] = (batch_y_transformed[0][1] - y_mean[2])/y_std[2]\n",
        "            batch_y[i, 3] = (batch_y_transformed[0][2] - y_mean[3])/y_std[3]\n",
        "            batch_y[i, 4] = (batch_y_transformed[0][3] - y_mean[4])/y_std[4]\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    # Fonction appelée à chaque nouveau batch : sélection et augmentation des données\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
        "        batch_y = self.y[self.indices1[idx * self.batch_size:(idx + 1) * self.batch_size]]\n",
        "        batch_x, batch_y = self.apply_augmentation(batch_x, batch_y)\n",
        "\n",
        "        batch_y = np.array(batch_y)\n",
        "        return np.array(batch_x), [batch_y[:,0], batch_y[:,1:5], batch_y[:,5:]]\n",
        "\n",
        "    # Fonction appelée à la fin d'un epoch ; on randomise les indices d'accès aux données\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUbm6gTMdJgy"
      },
      "outputs": [],
      "source": [
        "# Instanciation d'une Sequence\n",
        "train_gen = MangeoireSequence(x_train, y_train, 16, augmentations=AUGMENTATIONS_TRAIN)\n",
        "\n",
        "# Pour tester la séquence, nous sélectionnons les éléments du premier batch et les affichons\n",
        "batch_x, batch_y = train_gen.__getitem__(0)\n",
        "\n",
        "y_batch = np.zeros((batch_y[0].shape[0],1+4+num_classes))\n",
        "\n",
        "for i in range(batch_y[0].shape[0]):\n",
        "  y_batch[i, 0] = batch_y[0][i]\n",
        "  y_batch[i, 1:5] = batch_y[1][i]\n",
        "  y_batch[i, 5:] = batch_y[2][i]\n",
        "\n",
        "print_data_localisation(batch_x, y_batch, image_size=IMAGE_SIZE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
